{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spanish Text Data Analysis\n",
    "\n",
    "This notebook explores the Spanish text data we've collected, focusing on:\n",
    "\n",
    "1. Text distribution and statistics\n",
    "2. Common learner errors\n",
    "3. Vocabulary frequency analysis\n",
    "4. Sentence length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import json\n",
    "\n",
    "# Load SpaCy Spanish model\n",
    "try:\n",
    "    nlp = spacy.load('es_core_news_sm')\n",
    "except OSError:\n",
    "    !python -m spacy download es_core_news_sm\n",
    "    nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.family'] = 'Arial'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load processed learner corpus\n",
    "with open('../data/processed_text/processed_learner_corpus.json', 'r', encoding='utf-8') as f:\n",
    "    learner_data = pd.json_normalize(json.load(f))\n",
    "\n",
    "# Load processed Wikipedia text\n",
    "with open('../data/processed_text/processed_wikipedia.txt', 'r', encoding='utf-8') as f:\n",
    "    wikipedia_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Basic statistics\n",
    "print(f'Number of learner sentences: {len(learner_data)}')\n",
    "print(f'Number of unique error types: {len(learner_data[\'error_type\'].unique())}')\n",
    "\n",
    "# Sentence length distribution\n",
    "learner_data['original_length'] = learner_data['original'].apply(len)\n",
    "learner_data['corrected_length'] = learner_data['corrected'].apply(len)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=learner_data, x='original_length', bins=50, kde=True)\n",
    "plt.title('Distribution of Sentence Lengths in Learner Data')\n",
    "plt.xlabel('Sentence Length (characters)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Error type distribution\n",
    "error_counts = learner_data['error_type'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=error_counts.index, y=error_counts.values)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Distribution of Error Types in Learner Data')\n",
    "plt.xlabel('Error Type')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vocabulary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Tokenize Wikipedia text\n",
    "doc = nlp(wikipedia_text[:1000000])  # Process first 1M characters\n",
    "\n",
    "# Get vocabulary frequency\n",
    "vocabulary = Counter([token.text.lower() for token in doc if not token.is_stop and not token.is_punct])\n",
    "\n",
    "# Most common words\n",
    "common_words = vocabulary.most_common(20)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=[word[0] for word in common_words], y=[word[1] for word in common_words])\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Most Common Words in Spanish Text')\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
